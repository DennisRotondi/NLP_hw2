{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP2022 - Homework 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code for a fast processing of data and experiments execution for the second homework of the course Natural Language Processing 2022. It has been completely wrote by Dennis Rotondi 1834864 using the methodologies learned throughout the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "# imports and deterministic stuff\n",
    "import os, sys\n",
    "sys.path.append(os.path.join(\"..\")) #to access hw2 functions\n",
    "sys.path.append(os.path.join(\"../..\")) #to access model folder\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = './nlp_hw2.ipynb'\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pytorch_lightning as pl\n",
    "from collections import OrderedDict, Counter\n",
    "\n",
    "from utils import read_dataset\n",
    "import wandb\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True  # Note that this Deterministic mode can have a performance impact\n",
    "torch.backends.cudnn.benchmark = False\n",
    "_ = pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the bonus exercise and hw1, I want to start by looking at the data I have to better understand how to proceed in the pre-processing operations. I've read that there are problems with some (sentence-ground truth) pairs, since we are not allowed to do any change I'll directly discharge them for the training phase if needed. I'll do my analysis mostly for the english dataset since it is mandatory and larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_file = \"../../data/EN/train.json\"\n",
    "\n",
    "sentences, labels = read_dataset(en_file)\n",
    "print(\"Number of training sentences (EN): \"+ str(len(sentences.keys())))\n",
    "# I'm just playing with the field of a sentence_id to understand our data samples.\n",
    "sentence_id = '1996/a/50/18_supp__323:5'\n",
    "print(\"## SENTENCE {} ##\".format(sentence_id))\n",
    "for key in sentences[sentence_id]:\n",
    "    print(key)\n",
    "    print(sentences[sentence_id][key])\n",
    "print(\"## LABEL ##\")\n",
    "for key in labels[sentence_id]:\n",
    "    print(key)\n",
    "    print(labels[sentence_id][key])\n",
    "\n",
    "# let's check and count the different frames and roles\n",
    "verbatlas_frames = Counter()\n",
    "predicate_roles = Counter()\n",
    "\n",
    "for k in labels:\n",
    "    verbatlas_frames.update(labels[k]['predicates'])\n",
    "    for idx in labels[k]['roles']:\n",
    "        predicate_roles.update(labels[k]['roles'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"## VF ##\")\n",
    "print(verbatlas_frames)\n",
    "# list of frames in the training dataset\n",
    "l_vf = list(verbatlas_frames.keys())\n",
    "print(l_vf)\n",
    "print(len(l_vf))\n",
    "print(\"## RL ##\")\n",
    "print(predicate_roles)\n",
    "p_r = list(predicate_roles.keys())\n",
    "print(p_r)\n",
    "print(len(p_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are clearly not using all the 466 [verbatlas](https://verbatlas.org/) frames but less than 3/4 of them: 303. Working with fewer clusters surely increases the overall performances because the system can only focus on a subset of them. In the next code cell I want to check if in the dev-set I do not have other frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sentences, dev_labels = read_dataset(\"../../data/EN/dev.json\")\n",
    "print(\"Number of training sentences (EN): \"+ str(len(dev_sentences.keys())))\n",
    "for k in dev_labels:\n",
    "    verbatlas_frames.update(dev_labels[k]['predicates'])\n",
    "    for idx in dev_labels[k]['roles']:\n",
    "        predicate_roles.update(dev_labels[k]['roles'][idx])\n",
    "\n",
    "l_vf_dev = list(verbatlas_frames.keys())\n",
    "print(len(l_vf_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are only 4 more frames in the dev_set wrt the train_set, this information is useful for further consideration when I'll deal with the optional part of this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I'm starting to understand the samples, it's clear that our dataset does not need much pre-processing, since we already have words tokens and associated lemmas for each sentence. Some more useful statistics are on how long are the sentences on average, how many predicates they have and how the distribution of pos-tagging tokens correlate with roles and predicates. I'll rapidly compute them in what follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_size=len(tokens_s)\n",
    "sentences_size=list()\n",
    "k=0\n",
    "for s,l in zip(tokens_s,labels_s):\n",
    "    sentences_size.append(len(s))\n",
    "    for w,lab in zip(s,l):\n",
    "        if not w in vocab and lab!=\"O\":\n",
    "            k+=1\n",
    "print(\"important words lost\",k)\n",
    "k=0\n",
    "for s,l in zip(tokens_s,labels_s):\n",
    "    for w,lab in zip(s,l):\n",
    "        if not w in vocab and lab!=\"O\":\n",
    "            k+=1\n",
    "            break\n",
    "print(\"percentage of dirty sentences\",k/token_size) #sentences that contains an OOV word but with a significant label !=0\n",
    "\n",
    "sent_np=np.asarray(sentences_size)\n",
    "print(\"mean\", sent_np.mean())\n",
    "print(\"std\", sent_np.std())\n",
    "print(\"min\", sent_np.min())\n",
    "print(\"max\", sent_np.max())\n",
    "\n",
    "plt.figure(figsize=(8,8)) #to increase the plot size\n",
    "_ = plt.hist(sent_np, bins = 'auto') \n",
    "plt.title(\"Histogram of sentences size available\") \n",
    "plt.show()\n",
    "\n",
    "flat_labels = sum(labels_s,[]) #to flat the list\n",
    "count = Counter(flat_labels)\n",
    "plt.figure(figsize=(10,10))\n",
    "_ = plt.bar(count.keys(),count.values()) \n",
    "plt.title(\"Bar Plot of labels frequency\") \n",
    "plt.show() #it's possible to notice that most of them are between size 7 and 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to train our model. Pytorch-lightning allow that in such a way that it's easy to modularize everything and train with few lines of code all the different models. Moreover using wandb as logger I auto-plot the training evolution in high quality plots and it's also possible to save the training history of the different trials. This will be very useful for comparing the experiments in the report.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with notebook need an 'absolute' import\n",
      "{'need_train': True, 'batch_size': 256, 'n_cpu': 8, 'language_model_name': 'bert-base-uncased', 'lr': 0.001, 'wd': 0, 'embedding_dim': 768, 'hidden_dim': 512, 'bidirectional': True, 'num_layers': 2, 'dropout': 0.2, 'trainable_embeddings': False, 'role_classes': 27, 'srl_34_ckpt': 'model/srl_34_EN.ckpt'}\n"
     ]
    }
   ],
   "source": [
    "from datasets_srl import SRL_DataModule\n",
    "from implementation import HParams, SRL_34\n",
    "from dataclasses import dataclass, asdict\n",
    "from pprint import pprint\n",
    "from utils import read_dataset, evaluate_argument_classification, evaluate_argument_identification\n",
    "from mergedeep import merge\n",
    "\n",
    "# these are some parameters that allow as I said to modularize the training. We need to store the hypermarameters of the model (lr, wd, ...), the language\n",
    "# and the task on which we want to perform the training.\n",
    "hparams = asdict(HParams())\n",
    "print(hparams)\n",
    "languages = [\"EN\", \"ES\", \"FR\"]\n",
    "tasks = [\"34\", \"234\", \"1234\"]\n",
    "models = {\"34\": SRL_34}\n",
    "\n",
    "\n",
    "language = languages[0]\n",
    "task = tasks[0]\n",
    "epochs = 20\n",
    "SRL_Model = models[task]\n",
    "# after reading the dataset I merge the two dicts (sentences and labels) since there is a field in common (predicate)\n",
    "# and it's only a waste of space keeping it in memory 2 copies of it.\n",
    "sentences = merge(*read_dataset(\"../../data/\"+language+\"/train.json\"))\n",
    "sentences_test = merge(*read_dataset(\"../../data/\"+language+\"/dev.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "data = SRL_DataModule(hparams, task, sentences, sentences_test)\n",
    "model = SRL_Model(hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdenondi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dennis/Desktop/nlp2022-hw2/hw2/stud/wandb/run-20220712_005247-3val2yqq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/denondi/SRL_34/runs/3val2yqq\" target=\"_blank\">vague-pond-21</a></strong> to <a href=\"https://wandb.ai/denondi/SRL_34\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/dennis/Applications/anaconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/dennis/Desktop/nlp2022-hw2/model exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type      | Params\n",
      "------------------------------------------------\n",
      "0 | transformer_model | BertModel | 109 M \n",
      "1 | lstm              | LSTM      | 11.6 M\n",
      "2 | dropout           | Dropout   | 0     \n",
      "3 | classifier        | Linear    | 27.7 K\n",
      "------------------------------------------------\n",
      "11.6 M    Trainable params\n",
      "109 M     Non-trainable params\n",
      "121 M     Total params\n",
      "484.243   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 60/60 [02:01<00:00,  2.03s/it, loss=0.263, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric avg_val_loss improved. New best score: 0.216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 60/60 [02:01<00:00,  2.03s/it, loss=0.263, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'avg_val_loss' reached 0.21583 (best 0.21583), saving model to '/home/dennis/Desktop/nlp2022-hw2/model/SRL_34-epoch=00-avg_val_loss_vae=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 60/60 [02:09<00:00,  2.16s/it, loss=0.181, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric avg_val_loss improved by 0.059 >= min_delta = 0.0. New best score: 0.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 60/60 [02:09<00:00,  2.16s/it, loss=0.181, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 100: 'avg_val_loss' reached 0.15633 (best 0.15633), saving model to '/home/dennis/Desktop/nlp2022-hw2/model/SRL_34-epoch=01-avg_val_loss_vae=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 60/60 [02:02<00:00,  2.05s/it, loss=0.143, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric avg_val_loss improved by 0.033 >= min_delta = 0.0. New best score: 0.123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 60/60 [02:02<00:00,  2.05s/it, loss=0.143, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 150: 'avg_val_loss' reached 0.12291 (best 0.12291), saving model to '/home/dennis/Desktop/nlp2022-hw2/model/SRL_34-epoch=02-avg_val_loss_vae=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 60/60 [02:01<00:00,  2.02s/it, loss=0.123, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric avg_val_loss improved by 0.016 >= min_delta = 0.0. New best score: 0.107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 60/60 [02:01<00:00,  2.02s/it, loss=0.123, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 200: 'avg_val_loss' reached 0.10728 (best 0.10728), saving model to '/home/dennis/Desktop/nlp2022-hw2/model/SRL_34-epoch=03-avg_val_loss_vae=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 60/60 [02:01<00:00,  2.02s/it, loss=0.104, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric avg_val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 60/60 [02:01<00:00,  2.02s/it, loss=0.104, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 250: 'avg_val_loss' reached 0.09221 (best 0.09221), saving model to '/home/dennis/Desktop/nlp2022-hw2/model/SRL_34-epoch=04-avg_val_loss_vae=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 60/60 [02:01<00:00,  2.03s/it, loss=0.0878, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric avg_val_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 60/60 [02:01<00:00,  2.03s/it, loss=0.0878, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 300: 'avg_val_loss' reached 0.08195 (best 0.08195), saving model to '/home/dennis/Desktop/nlp2022-hw2/model/SRL_34-epoch=05-avg_val_loss_vae=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 60/60 [02:01<00:00,  2.02s/it, loss=0.0802, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric avg_val_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 60/60 [02:01<00:00,  2.02s/it, loss=0.0802, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 350: 'avg_val_loss' reached 0.07539 (best 0.07539), saving model to '/home/dennis/Desktop/nlp2022-hw2/model/SRL_34-epoch=06-avg_val_loss_vae=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 60/60 [02:06<00:00,  2.11s/it, loss=0.0709, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric avg_val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 60/60 [02:06<00:00,  2.11s/it, loss=0.0709, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 400: 'avg_val_loss' reached 0.07190 (best 0.07190), saving model to '/home/dennis/Desktop/nlp2022-hw2/model/SRL_34-epoch=07-avg_val_loss_vae=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 60/60 [01:12<00:00,  1.21s/it, loss=0.0653, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric avg_val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 60/60 [01:12<00:00,  1.21s/it, loss=0.0653, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 450: 'avg_val_loss' reached 0.06824 (best 0.06824), saving model to '/home/dennis/Desktop/nlp2022-hw2/model/SRL_34-epoch=08-avg_val_loss_vae=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 60/60 [00:49<00:00,  1.21it/s, loss=0.0568, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 500: 'avg_val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 60/60 [00:47<00:00,  1.27it/s, loss=0.0515, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric avg_val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 60/60 [00:47<00:00,  1.27it/s, loss=0.0515, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 550: 'avg_val_loss' reached 0.06317 (best 0.06317), saving model to '/home/dennis/Desktop/nlp2022-hw2/model/SRL_34-epoch=10-avg_val_loss_vae=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 60/60 [00:48<00:00,  1.25it/s, loss=0.0482, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric avg_val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 60/60 [00:48<00:00,  1.25it/s, loss=0.0482, v_num=2yqq]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 600: 'avg_val_loss' reached 0.06212 (best 0.06212), saving model to '/home/dennis/Desktop/nlp2022-hw2/model/SRL_34-epoch=11-avg_val_loss_vae=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:   0%|          | 0/60 [00:00<?, ?it/s, loss=0.0482, v_num=2yqq]         "
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "# Define the logger\n",
    "# https://www.wandb.com/articles/pytorch-lightning-with-weights-biases.\n",
    "# NOTE: to use wandb properly you need to login in wandb (need an account) \n",
    "# or use a different logger eg. TensorBoard, I'm used to this one so I'll go for it.\n",
    "wandb.require(\"service\")\n",
    "wandb_logger = WandbLogger(project=\"SRL_\"+task, log_model = True)\n",
    "wandb_logger.experiment.watch(model, log = 'all', log_freq = 1000)\n",
    "# Define the trainer\n",
    "metric_to_monitor = 'avg_val_loss'\n",
    "# we employ the early stopping technique to avoid hours of usuless training, pl gives it for free\n",
    "early_stop_callback = EarlyStopping(monitor = metric_to_monitor, min_delta = 0.00, patience = 3, verbose = True, mode = \"min\")\n",
    "# it is also useful to keep track of the best model during the epochs (if you remember I did all this manually last hw)or use a different logger,\n",
    "# we have a callback even for this.\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "                        save_top_k = 1,\n",
    "                        monitor = metric_to_monitor,\n",
    "                        mode = \"min\",\n",
    "                        dirpath = \"../../model\",\n",
    "                        filename = \"SRL_\"+task+\"-{epoch:02d}-{avg_val_loss:.4f}\",\n",
    "                        verbose = True\n",
    "                    )\n",
    "# the trainer collect all the useful informations so far for the training \n",
    "trainer = pl.Trainer(logger = wandb_logger,\n",
    "                    max_epochs = epochs, \n",
    "                    gpus = 1,\n",
    "                    callbacks = [early_stop_callback, checkpoint_callback])    \n",
    "# Start the training\n",
    "trainer.fit(model, data)\n",
    "# Log the trained model\n",
    "trainer.save_checkpoint(\"../../model/SRL_\"+task+\"_last.ckpt\")\n",
    "wandb.save(\"wandb/\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "model = SRL_34.load_from_checkpoint(\"../../\"+hparams[\"srl_34_ckpt\"]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(sentences_test, require_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Argument Classification\")\n",
    "print(evaluate_argument_classification(sentences_test, predict))\n",
    "print(\"Argument Identification\")\n",
    "print(evaluate_argument_identification(sentences_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load(\"../../model/srl_34_EN.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: NOW the confusion matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOREMOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "auto_model = AutoModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"Using a Transformer network is simple\"\n",
    "sequence2 = \"we ciao\"\n",
    "# tokens = tokenizer.tokenize(sequence)\n",
    "\n",
    "# # print(tokens)\n",
    "\n",
    "# ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "# # print(ids)\n",
    "\n",
    "tokenized_inputs = tokenizer([[sequence, \"simple\"],[sequence2, \"ciao\"]],padding=True, return_tensors=\"pt\")  # \"pt\" -> return PyTorch torch.Tensor objects, rather than a list of tokens\n",
    "\n",
    "print(tokenized_inputs)\n",
    "print(tokenized_inputs['input_ids'].shape)\n",
    "print(tokenized_inputs.word_ids(0))\n",
    "print(tokenized_inputs.word_ids(1))\n",
    "# NOTE: in the dataset use those word ids to average and simply filter for example... MAY NOT WORK:...\n",
    "sequence3 = [\"we\", \"ciao\"]\n",
    "print(\"second - use this one!!\")\n",
    "tokenized_inputs2 = tokenizer.batch_encode_plus([([sequence.split(), [\"simple\"]]),(sequence3,[\"ciao\"])], add_special_tokens=True, is_split_into_words=True, padding=True, return_tensors=\"pt\")  # \"pt\" -> return PyTorch torch.Tensor objects, rather than a list of tokens\n",
    "print(tokenized_inputs2)\n",
    "print(tokenized_inputs2['input_ids'].shape)\n",
    "print(tokenized_inputs2.word_ids(0))\n",
    "a, b, c = tokenizer.batch_encode_plus([([sequence.split(), [\"simple\"]]),(sequence3,[\"ciao\"])], add_special_tokens=True, is_split_into_words=True, padding=True, return_tensors=\"pt\")  # \"pt\" -> return PyTorch torch.Tensor objects, rather than a list of tokens \n",
    "print(\"aaa\")\n",
    "print(b)\n",
    "print(\"aaa\")\n",
    "# print(tokenized_inputs2.word_ids(1))\n",
    "# sequence_a = \"This is a short sequence.\"\n",
    "# sequence_b = \"This is a rather long sequence. It is at least longer than the sequence A.\"\n",
    "# print(\"test\")\n",
    "# padded_sequences = tokenizer([sequence_a, sequence_b], padding=True)\n",
    "# print(padded_sequences)\n",
    "\n",
    "transformers_outputs = auto_model(**tokenized_inputs)#['input_ids']\n",
    "# print(transformers_outputs)\n",
    "transformers_outputs_sum = torch.stack(transformers_outputs.hidden_states[-4:], dim=0).sum(dim=0)\n",
    "print(transformers_outputs_sum.shape)\n",
    "# I should remove 2 sep and 1 cls, 1 additional token -> final size 7\n",
    "\n",
    "\n",
    "\n",
    "# filter_toke = tokenized_inputs['input_ids'][:, 1:-3, ...]\n",
    "# print(filter_toke.shape)\n",
    "# labels  = tokenized_inputs.word_ids()[1:-3]\n",
    "# samp_size = filter_toke.shape[1]\n",
    "# M = torch.zeros(max(labels)+1, samp_size)\n",
    "# M[labels, torch.arange(samp_size)] = 1\n",
    "# print(M)\n",
    "# M = torch.nn.functional.normalize(M, p=1, dim=1)\n",
    "# print(M)\n",
    "# torch.mm(M, filter_toke[0]).shape\n",
    "\n",
    "# i want to have an ID to unde\n",
    "# item[\"role_id\"] = (item[\"role_labels\"] == self.labels_to_id[\"_\"]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = torch.Tensor([[\n",
    "                     [0.1, 0.1],    #-> group / class 1\n",
    "                     [0.2, 0.2],    #-> group / class 2\n",
    "                     [0.4, 0.4],    #-> group / class 2\n",
    "                     [0.0, 0.0]     #-> group / class 0\n",
    "              ],\n",
    "              [\n",
    "                     [0.1, 0.1],    #-> group / class 1\n",
    "                     [0.2, 0.2],    #-> group / class 1\n",
    "                     [0.0, 0.0],    #-> group / class 0\n",
    "                     [12.0, 12.0]   #-> group / class 0\n",
    "              ]])\n",
    "\n",
    "from transformers_embedder.embedder import TransformersEmbedder\n",
    "labels = torch.LongTensor([[1, 2, 2, 2],[1,2,0,2]])\n",
    "\n",
    "\n",
    "print(TransformersEmbedder.merge_scatter(samples, labels))\n",
    "print(TransformersEmbedder.merge_scatter(samples, labels).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code taken from Riccardo Orlando transformer embedding https://github.com/Riccorl/transformers-embedder\n",
    "# it is needed to average the wordpieces after the tokenization to have more reliable embeddig. This is \n",
    "# useful because for OOV words (or other languages) we can capture more informations than simply using\n",
    "# the first token. \n",
    "def merge_scatter(embeddings: torch.Tensor, indices: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Minimal version of ``scatter_mean``, from `pytorch_scatter\n",
    "    <https://github.com/rusty1s/pytorch_scatter/>`_\n",
    "    library, that is compatible for ONNX but works only for our case.\n",
    "    It is used to compute word level embeddings from the transformer output.\n",
    "    Args:\n",
    "        embeddings (:obj:`torch.Tensor`):\n",
    "            The embeddings tensor.\n",
    "        indices (:obj:`torch.Tensor`):\n",
    "            The sub-word indices.\n",
    "    Returns:\n",
    "        :obj:`torch.Tensor`\n",
    "    \"\"\"\n",
    "\n",
    "    def broadcast(src: torch.Tensor, other: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Broadcast ``src`` to match the shape of ``other``.\n",
    "        Args:\n",
    "            src (:obj:`torch.Tensor`):\n",
    "                The tensor to broadcast.\n",
    "            other (:obj:`torch.Tensor`):\n",
    "                The tensor to match the shape of.\n",
    "        Returns:\n",
    "            :obj:`torch.Tensor`: The broadcasted tensor.\n",
    "        \"\"\"\n",
    "        for _ in range(src.dim(), other.dim()):\n",
    "            src = src.unsqueeze(-1)\n",
    "        src = src.expand_as(other)\n",
    "        return src\n",
    "\n",
    "    def scatter_sum(src: torch.Tensor, index: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Sums the elements in ``src`` that have the same indices as in ``index``.\n",
    "        Args:\n",
    "            src (:obj:`torch.Tensor`):\n",
    "                The tensor to sum.\n",
    "            index (:obj:`torch.Tensor`):\n",
    "                The indices to sum.\n",
    "        Returns:\n",
    "            :obj:`torch.Tensor`: The summed tensor.\n",
    "        \"\"\"\n",
    "        index = broadcast(index, src)\n",
    "        size = list(src.size())\n",
    "        size[1] = index.max() + 1\n",
    "        print(size)\n",
    "        print(src.dtype)\n",
    "        out = torch.zeros(size, dtype=src.dtype, device=src.device)\n",
    "        return out.scatter_add_(1, index, src)\n",
    "\n",
    "    # replace padding indices with the maximum value inside the batch\n",
    "    indices[indices == -1] = torch.max(indices)\n",
    "    merged = scatter_sum(embeddings, indices)\n",
    "    ones = torch.ones(\n",
    "        indices.size(), dtype=embeddings.dtype, device=embeddings.device\n",
    "    )\n",
    "    count = scatter_sum(ones, indices)\n",
    "    count.clamp_(1)\n",
    "    count = broadcast(count, merged)\n",
    "    merged.true_divide_(count)\n",
    "    return merged[:,:-1,:] #added by me to remove a batch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1,2,None],dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers-embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "\n",
    "self.vae=VAE.load_from_checkpoint(hparams.vae.pth_folder)\n",
    "self.vae.freeze() #we do not want to train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp2022-hw2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4eed754111ede77ce2654f5ed00c707307144a8607362a4447b4b2089c46effd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
